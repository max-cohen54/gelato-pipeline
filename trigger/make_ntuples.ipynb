{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f157a7-b655-48eb-ae0c-dfdf3d083571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import ROOT\n",
    "import math\n",
    "import h5py\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import sys\n",
    "phi_res = 128/(2*math.pi)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Constants\n",
    "# --------------------------------------------------------------\n",
    "# Maximum numbers of each object\n",
    "NUM_JETS = 10\n",
    "NUM_ELECTRONS = 6\n",
    "NUM_MUONS = 6\n",
    "NUM_PHOTONS = 6\n",
    "NUM_L1 = 6\n",
    "\n",
    "# Min/max pt and eta values\n",
    "MIN_JET_PT = 0\n",
    "MIN_PHELMU_PT = 0\n",
    "MAX_ETA = 1000\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Trigger Menu Stuff\n",
    "# --------------------------------------------------------------\n",
    "def get_hlt_chains_with_prescale_one(filename):\n",
    "    # Open and load the JSON data\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Filter the entries that have \"prescaleCombined\" = 1\n",
    "    result = []\n",
    "    for item in data:\n",
    "        if item.get('prescaleCombined') == 1:\n",
    "            result.append(item['hltChain'])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_L1_chains_with_prescale_one(filename):\n",
    "    # Open and load the JSON data\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Filter the entries that have \"prescaleCombined\" = 1\n",
    "    result = []\n",
    "    for item in data:\n",
    "        if item.get('prescaleCombined') == 1:\n",
    "            result.append(item['l1Item'])\n",
    "    \n",
    "    return np.unique(result)\n",
    "\n",
    "HLT_trig_names = get_hlt_chains_with_prescale_one('/eos/home-m/mmcohen/gelato/trigger_menus/CombinedPrescale_l1_230_hlt_412.json')\n",
    "L1_trig_names = get_L1_chains_with_prescale_one('/eos/home-m/mmcohen/gelato/trigger_menus/CombinedPrescale_l1_230_hlt_412.json')\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Functions that read the TTree and make the data for HLTAD and L1AD\n",
    "# --------------------------------------------------------------\n",
    "def sort_and_pad(in_data, max_objects):\n",
    "    \"\"\"input an object of size (4, num_objects), as well as the maximum number of objects wanted.\n",
    "    in_data[0] corresponds to the pt array, and the other three are E, eta, phi.\"\"\"\n",
    "    \n",
    "    indices = np.argsort(in_data[0])[-max_objects:][::-1] # indices that sort the in_data by pt\n",
    "    arrs = []\n",
    "    for array in in_data:\n",
    "\n",
    "        # Sorting\n",
    "        sorted_arr = array[indices]\n",
    "\n",
    "        # Padding\n",
    "        if len(array) < max_objects:\n",
    "            sorted_arr = np.concatenate((sorted_arr, np.zeros(max_objects - len(array))))\n",
    "\n",
    "        arrs.append(sorted_arr)\n",
    "        \n",
    "    \n",
    "    arrs = np.array(arrs).T\n",
    "    return np.array(arrs)\n",
    "\n",
    "def make_mask(min_pt, max_eta, pt, eta):\n",
    "    \"\"\"Make a mask on pt and eta of event, in case I want to make any data cuts.\"\"\"\n",
    "\n",
    "    return [(pt > MIN_JET_PT) and (abs(eta) < MAX_ETA) for pt, eta in zip(pt, eta)]\n",
    "\n",
    "\n",
    "def get_data(event, c_name, vars=['pt', 'm', 'eta', 'phi'], mask=None):\n",
    "    \"\"\"\n",
    "    Extracts and processes data from a specified container within an event.\n",
    "\n",
    "    event: The event object containing the data.\n",
    "    c_name: Name of the container to get the data from.\n",
    "    vars: List of the variables to pull from the container.\n",
    "    mask: The mask to apply to the data, if applicable.\n",
    "    max_objects: Maximum number of objects to retain after sorting and padding.\n",
    "    return: Processed data from the specified container, after being sorted and padded.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for var in vars:\n",
    "        full_var_name = f\"{c_name}_{var}\"\n",
    "        var_data = getattr(event, full_var_name)\n",
    "\n",
    "        if mask is not None:\n",
    "            masked_data = np.asarray([x for x, m in zip(var_data, mask) if m])\n",
    "        else:\n",
    "            masked_data = np.asarray([x for x in var_data]) # for some reason this syntax runs way faster!?\n",
    "\n",
    "        data.append(masked_data)\n",
    "    return data\n",
    "    #return sort_and_pad(data, max_objects=max_objects)\n",
    "\n",
    "\n",
    "def make_ntuples(tree, output_dir, use_TLA_triggers=True):\n",
    "    if use_TLA_triggers == False:\n",
    "        HLT_trig_names_ = [item for item in HLT_trig_names if 'TLA' not in item]\n",
    "        L1_trig_names_ = [item for item in L1_trig_names if 'TLA' not in item]\n",
    "    else:\n",
    "        HLT_trig_names_ = HLT_trig_names\n",
    "        L1_trig_names_ = L1_trig_names\n",
    "\n",
    "    # Define lists to hold the data\n",
    "    HLT_jet_list = []\n",
    "    HLT_el_list = []\n",
    "    HLT_muon_list = []\n",
    "    HLT_ph_list = []\n",
    "    MET_list = []\n",
    "    pass_L1_unprescaled = []\n",
    "    pass_HLT_unprescaled = []\n",
    "    L1_muon_list = []\n",
    "    L1_eFex_tau_list = []\n",
    "    L1_MET_list = []\n",
    "    L1_jFexSR_jet_list = []\n",
    "    event_number_list = []\n",
    "    run_number_list = []\n",
    "    mu_list = []\n",
    "    avg_int_list = []\n",
    "    LB_list = []\n",
    "    pass_single_jet_trigger = []\n",
    "    \n",
    "    \n",
    "    # loop over events in the TTree and save the info to the lists\n",
    "    for i, event in enumerate(tree):\n",
    "\n",
    "        # Trigger Decisions\n",
    "        trig_data = [str(trigger) for trigger in event.passedTriggers]\n",
    "        pass_L1_unprescaled.append(1*any(trigger in L1_trig_names_ for trigger in trig_data)) # 0=no 1=yes\n",
    "        pass_HLT_unprescaled.append(1*any(trigger in HLT_trig_names_ for trigger in trig_data)) # 0=no 1=yes\n",
    "        pass_single_jet_trigger.append('HLT_j400_pf_ftf_preselj225_L1jJ180' in trig_data)\n",
    "\n",
    "        # Event/run number\n",
    "        event_number_list.append(event.eventNumber)\n",
    "        run_number_list.append(event.runNumber)\n",
    "        LB_list.append(event.lumiBlock)\n",
    "\n",
    "        # Pileup\n",
    "        mu_list.append(event.actualInteractionsPerCrossing)\n",
    "        avg_int_list.append(event.averageInteractionsPerCrossing)\n",
    "    \n",
    "        # HLT Jets\n",
    "        HLT_jet_data = get_data(event, 'HLT_jet', vars=['pt', 'eta', 'phi'])\n",
    "        HLT_jet_list.append(sort_and_pad(HLT_jet_data, max_objects=6))\n",
    "\n",
    "        # L1 SR Jets\n",
    "        L1_jFexSR_jet_data = get_data(event, 'L1_jFexSRJet', vars=['et', 'eta', 'phi'])\n",
    "        L1_jFexSR_jet_list.append(sort_and_pad(L1_jFexSR_jet_data, max_objects=6))\n",
    "    \n",
    "        # Electrons\n",
    "        el_data = get_data(event, 'HLT_el', vars=['pt', 'eta', 'phi'])\n",
    "        HLT_el_list.append(sort_and_pad(el_data, max_objects=3))\n",
    "    \n",
    "        # Muons\n",
    "        muon_data = get_data(event, 'HLT_muon', vars=['pt', 'eta', 'phi'])\n",
    "        HLT_muon_list.append(sort_and_pad(muon_data, max_objects=3))\n",
    "\n",
    "        # L1 Muons\n",
    "        L1_muon_data = get_data(event, 'L1Muon', vars=['et', 'eta', 'phi'])\n",
    "        L1_muon_list.append(sort_and_pad(L1_muon_data, max_objects=4))\n",
    "        \n",
    "        # Photons\n",
    "        ph_data = get_data(event, 'HLT_ph', vars=['pt', 'eta', 'phi'])\n",
    "        HLT_ph_list.append(sort_and_pad(ph_data, max_objects=3))\n",
    "\n",
    "        # L1 eTaus \n",
    "        L1_eFex_tau_data = get_data(event, 'L1Tau_eFex', vars=['et', 'eta', 'phi'])\n",
    "        L1_eFex_tau_list.append(sort_and_pad(L1_eFex_tau_data, max_objects=4))\n",
    "    \n",
    "\n",
    "        # HLT MET\n",
    "        MET_data = [np.float32(event.TrigMETMet), 0, np.float32(event.TrigMETMetPhi)]\n",
    "        MET_list.append(MET_data)\n",
    "\n",
    "        # L1 MET\n",
    "        L1_MET_data = [np.float32(event.L1METMet), 0, np.float32(event.L1METMetPhi)]\n",
    "        L1_MET_list.append(L1_MET_data)\n",
    "\n",
    "    # Scale and fix the L1 data\n",
    "    nmuon, nSRjet, netau = 4, 6, 4\n",
    "    scale_factor = 10\n",
    "    eta_factor = 40\n",
    "    phi_factor = phi_res\n",
    "\n",
    "    def fix_phi_range(phi_data):\n",
    "        # Map values to [0,2pi] range\n",
    "        phi_fixed = phi_data % (2*math.pi)\n",
    "        # Scale to [0,128) range and round to nearest integer\n",
    "        phi_scaled = np.round(phi_fixed * 128/(2*math.pi))\n",
    "        \n",
    "        # Take modulo 128 to handle edge cases\n",
    "        phi_binned = phi_scaled % 128\n",
    "        return phi_binned\n",
    "    \n",
    "    def load_and_scale(data, n_objects, scale_factor=10, eta_factor=40, phi_factor=phi_res):\n",
    "        data[:, :, 0] *= scale_factor  # Scale the pT value\n",
    "        data[:, :, 1] *= eta_factor  # Scale the angle value\n",
    "        data[:, :, 2] = fix_phi_range(data[:, :, 2])\n",
    "        return data.reshape(-1, 3 * n_objects)\n",
    "        \n",
    "    L1_jFexSR_jets = load_and_scale(np.array(L1_jFexSR_jet_list), nSRjet)\n",
    "    L1_eFex_taus = load_and_scale(np.array(L1_eFex_tau_list), netau)\n",
    "    L1_muons = load_and_scale(np.array(L1_muon_list), nmuon, scale_factor=10000)\n",
    "\n",
    "    # Scale and fix the L1 MET\n",
    "    L1_MET = np.array(L1_MET_list)\n",
    "    L1_MET[:, 0] *= 10\n",
    "    L1_MET[:, 2] = fix_phi_range(L1_MET[:, 2])\n",
    "    L1_MET_fixed = np.zeros((L1_MET.shape[0], 2))\n",
    "    L1_MET_fixed[:, 0] = L1_MET[:, 0]\n",
    "    L1_MET_fixed[:, 1] = L1_MET[:, 2]\n",
    "    L1_MET = L1_MET_fixed\n",
    "\n",
    "    # Concatenate the data\n",
    "    HLT_data = np.concatenate([np.array(HLT_jet_list), np.array(HLT_el_list), np.array(HLT_muon_list), np.array(HLT_ph_list), np.array(MET_list).reshape(-1, 1, 3)], axis=1)\n",
    "    L1_data = np.concatenate([L1_jFexSR_jets, L1_eFex_taus, L1_muons, L1_MET], axis=1)\n",
    "    L1_data = np.nan_to_num(L1_data, nan=0.0)\n",
    "    \n",
    "    # Flatten the HLT data (The L1 data is already flattened)\n",
    "    HLT_num_features = HLT_data.shape[1] * HLT_data.shape[2]\n",
    "    HLT_data = np.reshape(HLT_data, newshape=(-1, HLT_num_features))\n",
    "\n",
    "    # create a dictionary of the data\n",
    "    data_dict = {\n",
    "        'HLT_data': HLT_data,\n",
    "        'L1_data': L1_data,\n",
    "        'pass_single_jet_trigger': np.array(pass_single_jet_trigger),\n",
    "        'event_numbers': np.array(event_number_list),\n",
    "        'run_numbers': np.array(run_number_list),\n",
    "        'LBs': np.array(LB_list),\n",
    "        'mus': np.array(mu_list),\n",
    "        'avg_ints': np.array(avg_int_list),\n",
    "        'pass_L1_unprescaled': np.array(pass_L1_unprescaled),\n",
    "        'pass_HLT_unprescaled': np.array(pass_HLT_unprescaled),\n",
    "    }\n",
    "\n",
    "    # Get the current date in YYYYMMDD format\n",
    "    current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "    # Construct the filename with the date and run number\n",
    "    filename = f'{output_dir}/data_dict_{current_date}_{run_number_list[0]}.h5'\n",
    "\n",
    "    with h5py.File(filename, 'w') as hf:\n",
    "        for key, value in data_dict.items():\n",
    "            hf.create_dataset(key, data=value)\n",
    "\n",
    "    print(f'wrote to {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2215c524-3a27-4af1-a8c0-7188456f9e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16769 events...\n",
      "wrote to /eos/home-m/mmcohen/ad_trigger_development/ops/data/ntuples/data_dict_20250623_498335.h5\n"
     ]
    }
   ],
   "source": [
    "ttree_file = '/eos/home-m/mmcohen/ad_trigger_development/ops/data/trees/05-30-2025_ops_local_498335_lb201_-1/data-tree/data25_13p6TeV.00498335.physics_Main.merge.AOD.f1586_m2272.root'\n",
    "\n",
    "\n",
    "# Open the ROOT file and get the tree\n",
    "f = ROOT.TFile.Open(ttree_file)\n",
    "td = f.Get('output_tree')\n",
    "tree = td.Get(\"nominal\")\n",
    "nevents = tree.GetEntries()\n",
    "print(f\"Processing {nevents} events...\")\n",
    "if not tree:\n",
    "    sys.stderr.write(f\"Error: tree {args.tree} not found in {args.input_root}\\n\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Make the data\n",
    "make_ntuples(tree, output_dir='/eos/home-m/mmcohen/ad_trigger_development/ops/data/ntuples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048d22e-4d2a-4f76-87fc-ef4f9bccee0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
